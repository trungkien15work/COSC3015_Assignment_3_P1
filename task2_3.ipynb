{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Milestone I Natural Language Processing\n",
    "## Task 2&3\n",
    "#### Student Name: Hong Thai Ngoc Ha, Dao Sy Trung Kien, Dao Quang Minh\n",
    "#### Student ID: S4060340, S3979613, S4015939\n",
    "\n",
    "Date: 04/09/2024\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3 and Jupyter notebook\n",
    "\n",
    "Libraries used: please include all the libraries you used in your assignment, e.g.,:\n",
    "* pandas\n",
    "* re\n",
    "* numpy\n",
    "\n",
    "## Introduction\n",
    "In tasks 2 and 3, students need to create feature vectors for job advertisement descriptions and titles. Then, using the created vectors, build machine learning models to classify the category of a job advertisement text. Students should provide answers to two questions:\n",
    "\n",
    "Q1: Language model comparisons\n",
    "\n",
    "Q2: Does more information provide higher accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to import libraries as you need in this assessment, e.g.,\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Generating Feature Representations for Job Advertisement Descriptions and Titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load Vocabulary from Vocab Files and Extract Title, Description, and Webindex from Preprocessed Job Advertisement File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict to store vocabulary of both titles and descriptions\n",
    "vocab_all = {}\n",
    "index = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Load the description vocabulary from the vocab.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_des = {}\n",
    "with open('vocab.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        word, idx = line.strip().split(':')\n",
    "        vocab_des[word] = int(idx)\n",
    "        vocab_all[word] = int(idx)\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Load the title vocabulary from the vocab_title.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_title = {}\n",
    "with open('vocab_title.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        next_index = index\n",
    "        word, idx = line.strip().split(':')\n",
    "        vocab_title[word] = int(idx)\n",
    "        if word not in vocab_all:\n",
    "            vocab_all[word] = next_index\n",
    "            next_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Extract descriptions, titles, and webindexes from Preprocessed Job Advertisement File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lists to store the descriptions, titles, labels, and webindexes\n",
    "descriptions = []\n",
    "titles = []\n",
    "webindexes = []\n",
    "labels = []\n",
    "all_doc = []\n",
    "\n",
    "# Open and read the preprocessed_job_ads.txt file\n",
    "with open('preprocessed_job_ads.txt', 'r') as file:\n",
    "    # First, we skip the header\n",
    "    next(file)\n",
    "    # Next iterate through each line\n",
    "    for line in file:\n",
    "        # Split the line by commas\n",
    "        fields = line.strip().split(', ')\n",
    "        # Extract the 'title', 'webindex', 'labels', and 'description' fields\n",
    "        if len(fields) >= 5:\n",
    "            title = fields[1]\n",
    "            webindex = fields[2]\n",
    "            description = fields[4]\n",
    "            label = fields[5]\n",
    "            # Add the title, webindex, label, and description to the respective lists\n",
    "            titles.append(title)\n",
    "            webindexes.append(webindex)\n",
    "            descriptions.append(description)\n",
    "            labels.append(label)\n",
    "            all_doc.append(title)\n",
    "            all_doc.append(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Generating Count Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Descriptions Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CountVectorizer object with the vocabulary from the vocab dictionary\n",
    "c_vec_des = CountVectorizer(vocabulary=vocab_des)\n",
    "\n",
    "# Fit and transform descriptions using the c_vec_des\n",
    "X_c_des = c_vec_des.fit_transform(descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Titles Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CountVectorizer object with the vocabulary from the vocab_title dictionary\n",
    "c_vec_title = CountVectorizer(vocabulary=vocab_title)\n",
    "\n",
    "# Fit and transform titles using the c_vec_title\n",
    "X_c_title = c_vec_title.fit_transform(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Titles and Descriptions Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean vocabulary dict\n",
    "vocab_all = set(vocab_all)\n",
    "\n",
    "# Create a CountVectorizer object with the vocabulary from the vocab_all dictionary\n",
    "c_vec_all = CountVectorizer(vocabulary=vocab_all)\n",
    "\n",
    "# Fit and transform titles and description using the c_vec_all\n",
    "X_c_all = c_vec_all.fit_transform(all_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Generating TF-IDF Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Desccriptions TF-IDF Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TfidfVectorizer object with the vocabulary from the vocab dictionary\n",
    "tfidf_vec_des = TfidfVectorizer(vocabulary=vocab_des)\n",
    "\n",
    "# Fit and transform descriptions using the TfidfVectorizer\n",
    "X_tfidf_des = tfidf_vec_des.fit_transform(descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Titles TF-IDF Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TfidfVectorizer object with the vocabulary from the vocab_title dictionary\n",
    "tfidf_vec_title = TfidfVectorizer(vocabulary=vocab_title)\n",
    "\n",
    "# Fit and transform titles using the TfidfVectorizer\n",
    "X_tfidf_title = tfidf_vec_title.fit_transform(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Combination TF-IDF Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TfidfVectorizer object with the vocabulary from the vocab_all dictionary\n",
    "tfidf_vec_all = TfidfVectorizer(vocabulary=vocab_all)\n",
    "\n",
    "# Fit and transform titles and descriptions using the TfidfVectorizer\n",
    "X_tfidf_all = tfidf_vec_all.fit_transform(all_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Generating One-hot Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Descriptions One-hot Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Binary CountVectorizer object with the vocabulary from the vocab dictionary\n",
    "one_hot_vec_des = CountVectorizer(vocabulary=vocab_des, binary=True)\n",
    "\n",
    "# Fit and transform the descriptions using the one_hot_vector\n",
    "X_one_des = one_hot_vec_des.fit_transform(descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Titles One-hot Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Binary CountVectorizer object with the vocabulary from the vocab_title dictionary\n",
    "one_hot_vec_title = CountVectorizer(vocabulary=vocab_title, binary=True)\n",
    "\n",
    "# Fit and transform the titles using the CountVectorizer\n",
    "X_one_tilte = one_hot_vec_title.fit_transform(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Titles and Descriptions One-hot Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Binary CountVectorizer object with the vocabulary from the vocab_all dictionary\n",
    "one_hot_vec_all = CountVectorizer(vocabulary=vocab_all, binary=True)\n",
    "\n",
    "# Fit and transform the titles and descriptions using the CountVectorizer\n",
    "X_one_all = one_hot_vec_all.fit_transform(all_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Generating Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Word2Vec model on the tokenized descriptions\n",
    "word2vecdes_model = Word2Vec(sentences=descriptions, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Word2Vec model on the tokenized titles\n",
    "word2vectitle_model = Word2Vec(sentences=titles, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Word2Vec model on the tokenized titles and descriptions\n",
    "word2vecall_model = Word2Vec(sentences=all_doc, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Saving the Vector Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a txt file to store the Count Vector representation of job advertisement descriptions\n",
    "# With this following format: word_integer_index:word_freq\n",
    "output_file = 'count_vectors.txt'\n",
    "with open(output_file, 'w') as file:\n",
    "    for i, webindex in enumerate(webindexes):\n",
    "        sparse_row = X_c_des[i]\n",
    "        non_zero = sparse_row.nonzero()[1]\n",
    "        sparse_represent = []\n",
    "        for word_integer_index in non_zero:\n",
    "            word_freq = sparse_row[0, word_integer_index]\n",
    "            sparse_represent.append(f\"{word_integer_index}:{word_freq}\")\n",
    "        line = f\"#{webindex},\" + ','.join(sparse_represent) + '\\n'\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Job Advertisement Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "seed = 0\n",
    "\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits= num_folds, random_state=seed, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X_train,X_test,y_train, y_test,seed):\n",
    "    model = LogisticRegression(random_state=seed)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_based_on_kf(count_df, tfidf_df, onehot_df, num_of_folds):\n",
    "    title_cv_df = pd.DataFrame(columns = ['count','tfidf','onehot'],index=range(num_of_folds))\n",
    "\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf.split(list(range(0,len(labels)))):\n",
    "        y_train = [labels[i] for i in train_index]\n",
    "        y_test = [labels[i] for i in test_index]\n",
    "\n",
    "        title_cv_df.loc[fold,'count'] = evaluate(count_df[train_index],count_df[test_index],y_train,y_test,seed)\n",
    "        \n",
    "        title_cv_df.loc[fold,'tfidf'] = evaluate(tfidf_df[train_index],tfidf_df[test_index],y_train,y_test,seed)\n",
    "\n",
    "        title_cv_df.loc[fold,'onehot'] = evaluate(onehot_df[train_index],onehot_df[test_index],y_train,y_test,seed)\n",
    "        \n",
    "        fold +=1\n",
    "    return title_cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using LogisticRegression on description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 3\n",
    "cv_df = evaluate_based_on_kf(X_c_des, X_tfidf_des, X_one_des, num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>onehot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.864516</td>\n",
       "      <td>0.896774</td>\n",
       "      <td>0.870968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.858065</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.832258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.858065</td>\n",
       "      <td>0.877419</td>\n",
       "      <td>0.877419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.890323</td>\n",
       "      <td>0.929032</td>\n",
       "      <td>0.864516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count     tfidf    onehot\n",
       "0  0.884615  0.916667  0.903846\n",
       "1  0.864516  0.896774  0.870968\n",
       "2  0.858065  0.870968  0.832258\n",
       "3  0.858065  0.877419  0.877419\n",
       "4  0.890323  0.929032  0.864516"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8981720430107527"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df['tfidf'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using LogisticRegression on Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 3\n",
    "title_cv_df = evaluate_based_on_kf(X_c_title, X_tfidf_title, X_one_tilte, num_folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>onehot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.814103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.832258</td>\n",
       "      <td>0.845161</td>\n",
       "      <td>0.825806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.780645</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.787097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.832258</td>\n",
       "      <td>0.812903</td>\n",
       "      <td>0.812903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.83871</td>\n",
       "      <td>0.83871</td>\n",
       "      <td>0.83871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count     tfidf    onehot\n",
       "0  0.820513  0.820513  0.814103\n",
       "1  0.832258  0.845161  0.825806\n",
       "2  0.780645       0.8  0.787097\n",
       "3  0.832258  0.812903  0.812903\n",
       "4   0.83871   0.83871   0.83871"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8234574028122414"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_cv_df['tfidf'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification on title and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 3\n",
    "doc_cv_df = evaluate_based_on_kf(X_c_all, X_tfidf_all, X_one_all, num_folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>onehot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.525641</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.487179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.503226</td>\n",
       "      <td>0.522581</td>\n",
       "      <td>0.496774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.567742</td>\n",
       "      <td>0.587097</td>\n",
       "      <td>0.509677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.554839</td>\n",
       "      <td>0.535484</td>\n",
       "      <td>0.477419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.509677</td>\n",
       "      <td>0.477419</td>\n",
       "      <td>0.503226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count     tfidf    onehot\n",
       "0  0.525641  0.519231  0.487179\n",
       "1  0.503226  0.522581  0.496774\n",
       "2  0.567742  0.587097  0.509677\n",
       "3  0.554839  0.535484  0.477419\n",
       "4  0.509677  0.477419  0.503226"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.528362282878412"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_cv_df['tfidf'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "### Q1: Language model comparisons:\n",
    "From 'cv_df' DataFrame, we can clearly see that the tfidf vector gives the best result (highest accuracy is 0.85 while average is -.79).\n",
    "\n",
    "The model accuracy on 5-fold test is the highest on every fold. The onehot vector and count vector is pretty similar but the onehot vector is slightly better.\n",
    "### Q2: Impact of amount of information on the accuracy:\n",
    "Different approach of the data gives us different vocabulary to work with. In this assignment, we created 3 vocabulary based on 3 approaches:\n",
    "1. Build vocabulary based on titles\n",
    "2. Build vocabulary based on descriptions\n",
    "3. Build vocabulary based on titles AND descriptions\n",
    "\n",
    "The results of approaches (1) and (2) are not very differnt from each other (best model works on tfidf vector, the average accuracy is nearly 0.8) with the apprach (2) is slightly better.\n",
    "\n",
    "The approach (3) has the most information (gather text from both titles and descriptions) but it's performance is not as good as the other two.\n",
    "\n",
    "We can see that the descriptions can generate bigger vocabulary that the titles and their combination will generate an even bigger one. But the accuracy only improves for the case of titles to descriptions\n",
    "\n",
    "From the result above, it is safe to say that more information is not always improve the accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
