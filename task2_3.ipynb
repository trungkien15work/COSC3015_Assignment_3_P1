{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Milestone I Natural Language Processing\n",
    "## Task 2&3\n",
    "#### Student Name: Dao Sy Trung Kien\n",
    "#### Student ID: S3979613\n",
    "\n",
    "Date: 04/09/2024\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3 and Jupyter notebook\n",
    "\n",
    "Libraries used: please include all the libraries you used in your assignment, e.g.,:\n",
    "* pandas\n",
    "* re\n",
    "* numpy\n",
    "\n",
    "## Introduction\n",
    "In tasks 2 and 3, students need to create feature vectors for job advertisement descriptions and titles. Then, using the created vectors, build machine learning models to classify the category of a job advertisement text. Students should provide answers to two questions:\n",
    "Q1: Language model comparisons\n",
    "Q2: Does more information provide higher accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to import libraries as you need in this assessment, e.g.,\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Generating Feature Representations for Job Advertisement Descriptions and Titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load Vocabulary from Vocab Files and Extract Title, Description, and Webindex from Preprocessed Job Advertisement File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Load the description vocabulary from the vocab.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_des = {}\n",
    "with open('vocab.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        word, idx = line.strip().split(':')\n",
    "        vocab_des[word] = int(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Load the title vocabulary from the vocab_title.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_title = {}\n",
    "with open('vocab_title.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        word, idx = line.strip().split(':')\n",
    "        vocab_title[word] = int(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Extract descriptions, titles, and webindexes from Preprocessed Job Advertisement File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lists to store the descriptions, titles, labels, and webindexes\n",
    "descriptions = []\n",
    "titles = []\n",
    "webindexes = []\n",
    "labels = []\n",
    "all_doc = []\n",
    "\n",
    "# Open and read the preprocessed_job_ads.txt file\n",
    "with open('preprocessed_job_ads.txt', 'r') as file:\n",
    "    # First, we skip the header\n",
    "    next(file)\n",
    "    # Next iterate through each line\n",
    "    for line in file:\n",
    "        # Split the line by commas\n",
    "        fields = line.strip().split(', ')\n",
    "        # Extract the 'title', 'webindex', 'labels', and 'description' fields\n",
    "        if len(fields) >= 5:\n",
    "            title = fields[1]\n",
    "            webindex = fields[2]\n",
    "            description = fields[4]\n",
    "            label = fields[5]\n",
    "            # Add the title, webindex, label, and description to the respective lists\n",
    "            titles.append(title)\n",
    "            webindexes.append(webindex)\n",
    "            descriptions.append(description)\n",
    "            labels.append(label)\n",
    "            all_doc.append(title)\n",
    "            all_doc.append(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Generating Count Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Descriptions Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CountVectorizer object with the vocabulary from the vocab dictionary\n",
    "c_vec_des = CountVectorizer(vocabulary=vocab_des)\n",
    "\n",
    "# Fit and transform descriptions using the c_vec_des\n",
    "X_c_des = c_vec_des.fit_transform(descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Titles Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CountVectorizer object with the vocabulary from the vocab_title dictionary\n",
    "c_vec_title = CountVectorizer(vocabulary=vocab_title)\n",
    "\n",
    "# Fit and transform titles using the c_vec_title\n",
    "X_c_title = c_vec_title.fit_transform(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Generating TF-IDF Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Desccriptions TF-IDF Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TfidfVectorizer object with the vocabulary from the vocab dictionary\n",
    "tfidf_vec_des = TfidfVectorizer(vocabulary=vocab_des)\n",
    "\n",
    "# Fit and transform descriptions using the TfidfVectorizer\n",
    "X_tfidf_des = tfidf_vec_des.fit_transform(descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Titles TF-IDF Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TfidfVectorizer object with the vocabulary from the vocab_title dictionary\n",
    "tfidf_vec_title = TfidfVectorizer(vocabulary=vocab_title)\n",
    "\n",
    "# Fit and transform titles using the TfidfVectorizer\n",
    "X_tfidf_title = tfidf_vec_title.fit_transform(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Generating One-hot Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Descriptions One-hot Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Binary CountVectorizer object with the vocabulary from the vocab dictionary\n",
    "one_hot_vec_des = CountVectorizer(vocabulary=vocab_des, binary=True)\n",
    "\n",
    "# Fit and transform the descriptions using the one_hot_vector\n",
    "X_one_des = one_hot_vec_des.fit_transform(descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Titles One-hot Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Binary CountVectorizer object with the vocabulary from the vocab_title dictionary\n",
    "one_hot_vec_title = CountVectorizer(vocabulary=vocab_title, binary=True)\n",
    "\n",
    "# Fit and transform the descriptions using the CountVectorizer\n",
    "X_one_tilte = one_hot_vec_title.fit_transform(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Generating Word2Vec Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Word2Vec model on the tokenized descriptions\n",
    "word2vecdes_model = Word2Vec(sentences=descriptions, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count vectors exported to count_vectors.txt\n"
     ]
    }
   ],
   "source": [
    "# Train the Word2Vec model on the tokenized titles\n",
    "word2vectitle_model = Word2Vec(sentences=titles, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Saving the Vector Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file for writing the word vectors\n",
    "output_file = 'count_vectors.txt'\n",
    "with open(output_file, 'w') as file:\n",
    "    # Iterate over each description and its corresponding webindex\n",
    "    for idx, webindex in enumerate(webindexes):\n",
    "        # Get the sparse representation of the description\n",
    "        sparse_row = X_c_des[idx]\n",
    "        non_zero_indices = sparse_row.nonzero()[1]\n",
    "        sparse_represent = []\n",
    "        for word_idx in non_zero_indices:\n",
    "            word_count = sparse_row[0, word_idx]\n",
    "            sparse_represent.append(f\"{word_idx}:{word_count}\")\n",
    "        # Format line and write to the file\n",
    "        line = f\"#{webindex},\" + ','.join(sparse_represent) + '\\n'\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Job Advertisement Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "seed = 0\n",
    "\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits= num_folds, random_state=seed, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X_train,X_test,y_train, y_test,seed):\n",
    "    model = LogisticRegression(random_state=seed)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_based_on_kf(count_df, tfidf_df, onehot_df, num_of_folds):\n",
    "    title_cv_df = pd.DataFrame(columns = ['count','tfidf','onehot'],index=range(num_of_folds))\n",
    "\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf.split(list(range(0,len(labels)))):\n",
    "        y_train = [labels[i] for i in train_index]\n",
    "        y_test = [labels[i] for i in test_index]\n",
    "\n",
    "        title_cv_df.loc[fold,'count'] = evaluate(count_df[train_index],count_df[test_index],y_train,y_test,seed)\n",
    "        \n",
    "        title_cv_df.loc[fold,'tfidf'] = evaluate(tfidf_df[train_index],tfidf_df[test_index],y_train,y_test,seed)\n",
    "\n",
    "        title_cv_df.loc[fold,'onehot'] = evaluate(onehot_df[train_index],onehot_df[test_index],y_train,y_test,seed)\n",
    "        \n",
    "        fold +=1\n",
    "    return title_cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using LogisticRegression on description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 3\n",
    "cv_df = evaluate_based_on_kf(X_c, X_tfidf, X_one, num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>onehot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.775641</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.782051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.76129</td>\n",
       "      <td>0.787097</td>\n",
       "      <td>0.76129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.76129</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.774194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.780645</td>\n",
       "      <td>0.722581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.845161</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count     tfidf    onehot\n",
       "0  0.775641  0.794872  0.782051\n",
       "1   0.76129  0.787097   0.76129\n",
       "2   0.76129  0.767742  0.774194\n",
       "3  0.670968  0.780645  0.722581\n",
       "4  0.806452  0.845161       0.8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7951033912324235"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df['tfidf'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using LogisticRegression on Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocess titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stop words\n",
    "with open('stopwords_en.txt', 'r') as f:\n",
    "    stopwords = set(f.read().splitlines())\n",
    "\n",
    "# List to store the results\n",
    "results = []\n",
    "\n",
    "# Preprocess the text and store the results\n",
    "for directory in directories:\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, 'r', encoding= 'unicode_escape') as file:\n",
    "                content = file.read()\n",
    "                title = content.split(\"Title: \")[1].split(\"\\n\")[0]\n",
    "                webindex = content.split(\"Webindex: \")[1].split(\"\\n\")[0]\n",
    "                description = content.split(\"Description: \")[1].strip()\n",
    "                # Store the result\n",
    "                results.append({\n",
    "                    'Title': title,\n",
    "                    'Webindex': webindex,\n",
    "                    'Description': description\n",
    "                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict to store vocab created from titles and titles + descriptions\n",
    "title_vocab = {}\n",
    "all_vocab = {}\n",
    "\n",
    "\n",
    "# List to store temporary tokens\n",
    "tokens = []\n",
    "tokens_lower = []\n",
    "\n",
    "# Token's regex pattern\n",
    "pattern = r\"[a-zA-Z]+(?:[-'][a-zA-Z]+)?\"\n",
    "tokenizer = RegexpTokenizer(pattern) \n",
    "\n",
    "# Tokenize titles\n",
    "for title in titles:\n",
    "    token = tokenizer.tokenize(description)\n",
    "    tokens.append(token)\n",
    "\n",
    "# Filter tokens that only has one word, then lowercase transform them\n",
    "for tokene in tokens:\n",
    "    token_list = []\n",
    "    for token in tokene:\n",
    "        if len(token) >= 2 and token not in stopwords:\n",
    "            token_list.append(token)\n",
    "        token_list.append(token.lower())\n",
    "    tokens_lower.append(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictonary that contain the frequency of term\n",
    "term_frequency = defaultdict(int)\n",
    "\n",
    "for tokens in tokens_lower:\n",
    "    for token in tokens: \n",
    "        term_frequency[token] += 1\n",
    "\n",
    "tokens_more_than_1 = []\n",
    "\n",
    "# Remove tokens that only appears once\n",
    "for tokens in tokens_lower:\n",
    "    tokens_filtered_freq = []\n",
    "    for token in tokens:\n",
    "        if term_frequency[token] > 1:\n",
    "            tokens_filtered_freq.append(token)\n",
    "    tokens_more_than_1.append(tokens_filtered_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictonary that contain the document frequency\n",
    "document_frequency = defaultdict(int)\n",
    "\n",
    "for document in tokens_more_than_1:\n",
    "    for word in document:\n",
    "        document_frequency[word] += 1\n",
    "        \n",
    "# Remove tokens that appears more than 50 times\n",
    "more_than_50 = []\n",
    "for word, count in document_frequency.items():\n",
    "    more_than_50.append((word,count))\n",
    "    more_than_50.sort(key=lambda x: x[1], reverse=True)\n",
    "    if len(more_than_50) > 50:\n",
    "        more_than_50.pop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = []\n",
    "# Finalise tokens list, filter out too short tokens and tokens that appears too many times\n",
    "for tokens in tokens_more_than_1:\n",
    "    token_list = []\n",
    "    for token in tokens:\n",
    "        if token not in more_than_50:\n",
    "            token_list.append(token)\n",
    "    final_list.append(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the titles vocabulary\n",
    "title_vocabulary = []\n",
    "for tokens in final_list:\n",
    "    for token in tokens:\n",
    "        if token not in title_vocabulary:\n",
    "            title_vocabulary.append(token)\n",
    "\n",
    "for idx in range(len(title_vocabulary)):\n",
    "    word = title_vocabulary[idx]\n",
    "    title_vocab[word] = int(idx)\n",
    "    if word not in document_vocabulary:\n",
    "        document_vocabulary.append(word)\n",
    "\n",
    "# Add new word to the document vocabulary\n",
    "for idx in range(len(document_vocabulary)):\n",
    "    word = document_vocabulary[idx]\n",
    "    all_vocab[word] = int(idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CountVectorizer with the custom vocabulary\n",
    "c_title_vector = CountVectorizer(vocabulary=title_vocab)\n",
    "c_doc_vector = CountVectorizer(vocabulary=all_vocab)\n",
    "\n",
    "# Fit and transform the descriptions using the c_vector\n",
    "X_title_c = c_vector.fit_transform(titles)\n",
    "X_doc_c = c_vector.fit_transform(all_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TfidfVectorizer with the custom vocabulary\n",
    "tfidf_title_vector = TfidfVectorizer(vocabulary=title_vocab)\n",
    "tfidf_doc_vector = TfidfVectorizer(vocabulary=all_vocab)\n",
    "\n",
    "# Fit and transform the descriptions using the TfidfVectorizer\n",
    "X_title_tfidf = tfidf_vector.fit_transform(titles)\n",
    "X_doc_tfidf = tfidf_vector.fit_transform(all_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CountVectorizer with the custom vocabulary and binary option\n",
    "one_hot_title_vector = CountVectorizer(vocabulary=title_vocab, binary=True)\n",
    "one_hot_doc_vector = CountVectorizer(vocabulary=all_vocab, binary=True)\n",
    "\n",
    "# Fit and transform the descriptions using the CountVectorizer\n",
    "X_title_one = one_hot_vector.fit_transform(titles)\n",
    "X_doc_one = one_hot_vector.fit_transform(all_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using LogisticRegression on title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 3\n",
    "title_cv_df = evaluate_based_on_kf(X_title_c, X_title_tfidf, X_title_one, num_folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>onehot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.705128</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.705128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.787097</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.780645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.748387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.787097</td>\n",
       "      <td>0.787097</td>\n",
       "      <td>0.787097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.787097</td>\n",
       "      <td>0.787097</td>\n",
       "      <td>0.774194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count     tfidf    onehot\n",
       "0  0.705128  0.711538  0.705128\n",
       "1  0.787097       0.8  0.780645\n",
       "2  0.741935  0.767742  0.748387\n",
       "3  0.787097  0.787097  0.787097\n",
       "4  0.787097  0.787097  0.774194"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7706947890818858"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_cv_df['tfidf'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification on title and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 3\n",
    "doc_cv_df = evaluate_based_on_kf(X_doc_c, X_doc_tfidf, X_doc_one, num_folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>onehot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.448718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.535484</td>\n",
       "      <td>0.554839</td>\n",
       "      <td>0.516129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.535484</td>\n",
       "      <td>0.606452</td>\n",
       "      <td>0.503226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.522581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.529032</td>\n",
       "      <td>0.574194</td>\n",
       "      <td>0.503226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count     tfidf    onehot\n",
       "0  0.480769  0.487179  0.448718\n",
       "1  0.535484  0.554839  0.516129\n",
       "2  0.535484  0.606452  0.503226\n",
       "3  0.580645       0.6  0.522581\n",
       "4  0.529032  0.574194  0.503226"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5645326716294459"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_cv_df['tfidf'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "### Q1: Language model comparisons:\n",
    "From 'cv_df' DataFrame, we can clearly see that the tfidf vector gives the best result (highest accuracy is 0.85 while average is -.79).\n",
    "\n",
    "The model accuracy on 5-fold test is the highest on every fold. The onehot vector and count vector is pretty similar but the onehot vector is slightly better.\n",
    "### Q2: Impact of amount of information on the accuracy:\n",
    "Different approach of the data gives us different vocabulary to work with. In this assignment, we created 3 vocabulary based on 3 approaches:\n",
    "1. Build vocabulary based on titles\n",
    "2. Build vocabulary based on descriptions\n",
    "3. Build vocabulary based on titles AND descriptions\n",
    "\n",
    "The results of approaches (1) and (2) are not very differnt from each other (best model works on tfidf vector, the average accuracy is nearly 0.8) with the apprach (2) is slightly better.\n",
    "\n",
    "The approach (3) has the most information (gather text from both titles and descriptions) but it's performance is not as good as the other two.\n",
    "\n",
    "We can see that the descriptions can generate bigger vocabulary that the titles and their combination will generate an even bigger one. But the accuracy only improves for the case of titles to descriptions\n",
    "\n",
    "From the result above, it is safe to say that more information is not always improve the accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
